# Развертывание Kafka кластера с использованием Docker Compose

Этот проект демонстрирует развертывание локального Kafka кластера с использованием Docker Compose и работу с данными через Kafka.

## Описание задачи

Задача включает следующие шаги:
1. Развернуть локальный Kafka кластер с помощью Docker Compose.
2. Создать топик example_topic.
3. Сгенерировать данные о действиях клиентов маркетплейса (например, клики и покупки).
4. Загрузить эти данные в созданный топик.
5. Создать консьюмера для анализа данных и вывести пользователей с наибольшим количеством действий (click, purchase).

## Установка и запуск

### Требования

- Docker
- Docker Compose

### Шаги по установке

1. Клонирование репозитория:
    
   
2. Перейти в директорию проекта:
      

3. Запуск контейнеров с помощью Docker Compose: ``` docker-compose up -d ```
   

### Создание топика

После запуска контейнеров создаем топик example_topic:

``` docker exec -it kafka /bin/bash ```

``` kafka-topics --create --bootstrap-server localhost:9092 --topic example_topic --partitions 1 --replication-factor 1
```


### Генерация и отправка данных

Для генерации и отправки данных можно воспользоваться скриптом generate_data.py. 
Пример использования:

python generate_data.py


### Анализ данных

Запустите консьюмера для анализа данных:

``` docker exec -it kafka /bin/bash ```
``` kafka-console-consumer --bootstrap-server localhost:9092 --topic example_topic --from-beginning
```


### Вывод пользователей с наибольшим количеством действий

Для этого можно использовать консольную команду или написать простой анализатор на Python. Пример вывода данных в консоли:

<output of analysis>
